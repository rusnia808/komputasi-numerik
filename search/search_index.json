{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Selamat Datang Di Halaman Tugas Penambangan Data \u00b6 Nama : Rusnia Dyah Wardani NIM : 180411100018 Kelas : Penambangan Data 5D Jurusan : Teknik Informatika Alamat : Perum. Telang Indah Gg Masjid \u00b6 \u200b","title":"Index"},{"location":"#selamat-datang-di-halaman-tugas-penambangan-data","text":"Nama : Rusnia Dyah Wardani NIM : 180411100018 Kelas : Penambangan Data 5D Jurusan : Teknik Informatika Alamat : Perum. Telang Indah Gg Masjid","title":"Selamat Datang Di Halaman Tugas Penambangan Data"},{"location":"clus/","text":"CLUSTERING CATEGORICAL DATA \u00b6 Clustering adalah sebuah proses untuk mengelompokan data ke dalam beberapa cluster atau kelompok sehingga data dalam satu cluster memiliki tingkat kemiripan yang maksimum dan data antar cluster memiliki kemiripan yang minimum. Metode K-Means Clustering \u00b6 K-Means adalah salah satu algoritma clustering / pengelompokan data yang bersifat Unsupervised Learning, yang berarti masukan dari algoritma ini menerima data tanpa label kelas. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. Karakteristik dari algoritma ini adalah : Memiliki n buah data Input berupa jumlah data dan jumlah cluster (kelompok) Pada setiap cluster / kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut. Algoritma K-Means \u00b6 Secara sederhana algoritma K-Means dimulai dari tahap berikut : Pilih K buah titik centroid. Menghitung jarak data dengan centroid. Update nilai titik centroid. Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah. Rumus K-Means \u00b6 Metode K-Modes \u00b6 K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster. Rumus K-Modes \u00b6 Metode K-Prototype \u00b6 Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu. Rumus K-Prototype \u00b6 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Clustering Categorical Data"},{"location":"clus/#clustering-categorical-data","text":"Clustering adalah sebuah proses untuk mengelompokan data ke dalam beberapa cluster atau kelompok sehingga data dalam satu cluster memiliki tingkat kemiripan yang maksimum dan data antar cluster memiliki kemiripan yang minimum.","title":"CLUSTERING CATEGORICAL DATA"},{"location":"clus/#metode-k-means-clustering","text":"K-Means adalah salah satu algoritma clustering / pengelompokan data yang bersifat Unsupervised Learning, yang berarti masukan dari algoritma ini menerima data tanpa label kelas. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. Karakteristik dari algoritma ini adalah : Memiliki n buah data Input berupa jumlah data dan jumlah cluster (kelompok) Pada setiap cluster / kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut.","title":"Metode K-Means Clustering"},{"location":"clus/#algoritma-k-means","text":"Secara sederhana algoritma K-Means dimulai dari tahap berikut : Pilih K buah titik centroid. Menghitung jarak data dengan centroid. Update nilai titik centroid. Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah.","title":"Algoritma K-Means"},{"location":"clus/#rumus-k-means","text":"","title":"Rumus K-Means"},{"location":"clus/#metode-k-modes","text":"K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster.","title":"Metode K-Modes"},{"location":"clus/#rumus-k-modes","text":"","title":"Rumus K-Modes"},{"location":"clus/#metode-k-prototype","text":"Tujuan dari simulasi ini adalah mencoba menerapkan algoritma K-Prototype pada data campuran numerik dan kategorikal. Ada tahap preparation diperlakukan terhadap data point numerik normalisasi terlebih dahulu.","title":"Metode K-Prototype"},{"location":"clus/#rumus-k-prototype","text":"MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Rumus K-Prototype"},{"location":"error/","text":"ERROR DALAM KOMPUTASI NUMERIK \u00b6 Komputasi Numerik \u00b6 Komputasi numerik bisa dikatakan sebagai penentuan error suatu perhitungan untuk mencapai nilai akurasi. Komputer Numerik bertujuan untuk menentukan suatu akurasi dari hasil perhitungan atau percobaan. Komputer Numerik ini banyak sekali diimplementasikan dalam kehidupan termasuk dunia kedokteran, teknik, ekonomi, dan sains. Error Dalam Komputasi Numerik \u00b6 Error disini adalah nilai yang menyebabkan nilai tersebut tidak tepat. Error dapat terjadi karena adanya perbedaan antara hasil penyelesaian suatu model matematik secara numeric dengan penyelesaian secara analitis. Penyebab Terjadinya Error \u00b6 Error dapat terjadi karena beberapa kesalahan. Berikut ini penjelasan mengenai ketiga sumber kesalahan dalam komputasi numerik. Rund off errors Kesalahan jenis ini terjadi akibat proses pembulatan dalam perhitungan. Secara umum, proses pembulatan ada 2 aturan yaitu jika digit yang dibulatkan kurang dari 5, maka tidak terjadi pembulatan. Sebaliknya, jika lebih dari 5, maka terjadi pembulatan yaitu dengan menambah satu. Truncation errors Truncation errors adalah kesalahan yang dilakukan dengan memotong jumlah tak hingga dan memperkirakannya dengan jumlah terbatas. Inherent errors Terjadi akibat kekeliruan dalam menyalin data, salah membaca skala atau kesalahan karena kurangnya pengertian mengenai hukum-hukum fisik dari data yang diukur. Kesalahan ini sering terjadi karena faktor human error. DERET MACLAURIN \u00b6 Deret MacLaurin adalah Suatu fungsi f(x) yang memiliki turunan , , , dan seterusnya yang kontinyu dalam interval dengan maka untuk disekitar yaitu , dapat diekspansi kedalam Deret Taylor. Perhitungan e 2x \u00b6 Dalam banyak masalah terapan, pilihan basis yang mudah digunakan adalah bilangan irasional e = 2,718281828... Bilangan ini disebut basis natural. Fungsi f ( x ) = ex disebut sebagai fungsi eksponensial natural. Gambar 7 menunjukkan grafik fungsi ini. Pastikan bahwa dalam melihat fungsi eksponensial f ( x ) = ex , e adalah konstanta 2,718281828\u2026, sedangkan x adalah variabel. f(x)=ex f'(x) = ex f'(0) = 1 f\u201d(x) = ex f\u201d(0) = 1 f\u201d'(x) = ex f\u201d'(0) = 1 Untuk bilangan e 2x maka: jadi, kesimpulannya adalah sebagai berikut: ketika nilai x diganti dengan 4 maka hasilnya adalah 296,99. Listing Program \u00b6 Untuk membuat program agar dapat mengekspansi bilangan e 3x dengan nilai x=4 hingga nilai menjadi kurang dari 0,001 bisa dibuat dengan listing program sebagai berikut. x = int ( input ( \"masukan nilai x=\" )) coba = 1 a = 0 b = 1 while coba > 0.001 : f_x = 0 f_y = 0 for i in range ( a ): f_x += ( 3 * i ) * x * i / math . factorial ( i ) for j in range ( b ): f_y += ( 3 * j ) * x * j / math . factorial ( j ) print ( \"suku ke\" , a , \"=\" , f_x ) print ( \"suku ke\" , b , \"=\" , f_y ) coba = f_y - f_x a += 1 b += 1 print ( \"hasil seliih =\" , coba ) dan berikut hasil output nya : masukkan x = 1 suku ke 0 = 0 suku ke 1 = 1.0 selisih sukunya = 1.0 suku ke 1 = 1.0 suku ke 2 = 3.0 selisih sukunya = 2.0 suku ke 2 = 3.0 suku ke 3 = 5.0 selisih sukunya = 2.0 suku ke 3 = 5.0 suku ke 4 = 6.333333333333333 selisih sukunya = 1.333333333333333 suku ke 4 = 6.333333333333333 suku ke 5 = 7.0 selisih sukunya = 0.666666666666667 suku ke 5 = 7.0 suku ke 6 = 7.266666666666667 selisih sukunya = 0.2666666666666666 suku ke 6 = 7.266666666666667 suku ke 7 = 7.355555555555555 selisih sukunya = 0.08888888888888857 suku ke 7 = 7.355555555555555 suku ke 8 = 7.3809523809523805 selisih sukunya = 0.025396825396825307 suku ke 8 = 7.3809523809523805 suku ke 9 = 7.387301587301587 selisih sukunya = 0.006349206349206327 suku ke 9 = 7.387301587301587 suku ke 10 = 7.3887125220458545 selisih sukunya = 0.0014109347442676778 suku ke 10 = 7.3887125220458545 suku ke 11 = 7.388994708994708 selisih sukunya = 0.0002821869488531803","title":"Error in Numerical Computation"},{"location":"error/#error-dalam-komputasi-numerik","text":"","title":"ERROR DALAM KOMPUTASI NUMERIK"},{"location":"error/#komputasi-numerik","text":"Komputasi numerik bisa dikatakan sebagai penentuan error suatu perhitungan untuk mencapai nilai akurasi. Komputer Numerik bertujuan untuk menentukan suatu akurasi dari hasil perhitungan atau percobaan. Komputer Numerik ini banyak sekali diimplementasikan dalam kehidupan termasuk dunia kedokteran, teknik, ekonomi, dan sains.","title":"Komputasi Numerik"},{"location":"error/#error-dalam-komputasi-numerik_1","text":"Error disini adalah nilai yang menyebabkan nilai tersebut tidak tepat. Error dapat terjadi karena adanya perbedaan antara hasil penyelesaian suatu model matematik secara numeric dengan penyelesaian secara analitis.","title":"Error Dalam Komputasi Numerik"},{"location":"error/#penyebab-terjadinya-error","text":"Error dapat terjadi karena beberapa kesalahan. Berikut ini penjelasan mengenai ketiga sumber kesalahan dalam komputasi numerik. Rund off errors Kesalahan jenis ini terjadi akibat proses pembulatan dalam perhitungan. Secara umum, proses pembulatan ada 2 aturan yaitu jika digit yang dibulatkan kurang dari 5, maka tidak terjadi pembulatan. Sebaliknya, jika lebih dari 5, maka terjadi pembulatan yaitu dengan menambah satu. Truncation errors Truncation errors adalah kesalahan yang dilakukan dengan memotong jumlah tak hingga dan memperkirakannya dengan jumlah terbatas. Inherent errors Terjadi akibat kekeliruan dalam menyalin data, salah membaca skala atau kesalahan karena kurangnya pengertian mengenai hukum-hukum fisik dari data yang diukur. Kesalahan ini sering terjadi karena faktor human error.","title":"Penyebab Terjadinya Error"},{"location":"error/#deret-maclaurin","text":"Deret MacLaurin adalah Suatu fungsi f(x) yang memiliki turunan , , , dan seterusnya yang kontinyu dalam interval dengan maka untuk disekitar yaitu , dapat diekspansi kedalam Deret Taylor.","title":"DERET MACLAURIN"},{"location":"error/#perhitungan-e2x","text":"Dalam banyak masalah terapan, pilihan basis yang mudah digunakan adalah bilangan irasional e = 2,718281828... Bilangan ini disebut basis natural. Fungsi f ( x ) = ex disebut sebagai fungsi eksponensial natural. Gambar 7 menunjukkan grafik fungsi ini. Pastikan bahwa dalam melihat fungsi eksponensial f ( x ) = ex , e adalah konstanta 2,718281828\u2026, sedangkan x adalah variabel. f(x)=ex f'(x) = ex f'(0) = 1 f\u201d(x) = ex f\u201d(0) = 1 f\u201d'(x) = ex f\u201d'(0) = 1 Untuk bilangan e 2x maka: jadi, kesimpulannya adalah sebagai berikut: ketika nilai x diganti dengan 4 maka hasilnya adalah 296,99.","title":"Perhitungan e2x"},{"location":"error/#listing-program","text":"Untuk membuat program agar dapat mengekspansi bilangan e 3x dengan nilai x=4 hingga nilai menjadi kurang dari 0,001 bisa dibuat dengan listing program sebagai berikut. x = int ( input ( \"masukan nilai x=\" )) coba = 1 a = 0 b = 1 while coba > 0.001 : f_x = 0 f_y = 0 for i in range ( a ): f_x += ( 3 * i ) * x * i / math . factorial ( i ) for j in range ( b ): f_y += ( 3 * j ) * x * j / math . factorial ( j ) print ( \"suku ke\" , a , \"=\" , f_x ) print ( \"suku ke\" , b , \"=\" , f_y ) coba = f_y - f_x a += 1 b += 1 print ( \"hasil seliih =\" , coba ) dan berikut hasil output nya : masukkan x = 1 suku ke 0 = 0 suku ke 1 = 1.0 selisih sukunya = 1.0 suku ke 1 = 1.0 suku ke 2 = 3.0 selisih sukunya = 2.0 suku ke 2 = 3.0 suku ke 3 = 5.0 selisih sukunya = 2.0 suku ke 3 = 5.0 suku ke 4 = 6.333333333333333 selisih sukunya = 1.333333333333333 suku ke 4 = 6.333333333333333 suku ke 5 = 7.0 selisih sukunya = 0.666666666666667 suku ke 5 = 7.0 suku ke 6 = 7.266666666666667 selisih sukunya = 0.2666666666666666 suku ke 6 = 7.266666666666667 suku ke 7 = 7.355555555555555 selisih sukunya = 0.08888888888888857 suku ke 7 = 7.355555555555555 suku ke 8 = 7.3809523809523805 selisih sukunya = 0.025396825396825307 suku ke 8 = 7.3809523809523805 suku ke 9 = 7.387301587301587 selisih sukunya = 0.006349206349206327 suku ke 9 = 7.387301587301587 suku ke 10 = 7.3887125220458545 selisih sukunya = 0.0014109347442676778 suku ke 10 = 7.3887125220458545 suku ke 11 = 7.388994708994708 selisih sukunya = 0.0002821869488531803","title":"Listing Program"},{"location":"fuzzy clustering/","text":"fuzzy clustering \u00b6 pengertian fuzzy clustering: \u00b6 Fuzzy C-Means (FCM) merupakan teknik meengelompokan data yang keberadaan data dalam suatu kelompok ditentukan oleh nilai atau derajat keanggotaan tertentu berikut adalah algoriyma dari FCM: https://docs.google.com/spreadsheets/d/1yD6loNq8VoutgNbvjuEeGCqHpgYzwabY/edit#gid=1490456583 berikut contoh code fuzzy C-Means from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0}; FPC = {1:.2f}' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'series ' + str ( j )) ax2 . legend () newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"Fuzzy Clustering"},{"location":"fuzzy clustering/#fuzzy-clustering","text":"","title":"fuzzy clustering"},{"location":"fuzzy clustering/#pengertian-fuzzy-clustering","text":"Fuzzy C-Means (FCM) merupakan teknik meengelompokan data yang keberadaan data dalam suatu kelompok ditentukan oleh nilai atau derajat keanggotaan tertentu berikut adalah algoriyma dari FCM: https://docs.google.com/spreadsheets/d/1yD6loNq8VoutgNbvjuEeGCqHpgYzwabY/edit#gid=1490456583 berikut contoh code fuzzy C-Means from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0}; FPC = {1:.2f}' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'series ' + str ( j )) ax2 . legend () newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"pengertian fuzzy clustering:"},{"location":"jarak/","text":"Menghitung Jarak Data \u00b6 Jarak Minkowski \u00b6 Jarak Minkowski adalah metrik dalam ruang vektor numerik yang dapat dianggap sebagai generalisasi dari jarak Euclidean dan jarak Manhattan. Jarak Minkowski dapat digambarkan dengan : $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Keterangan : m = bilangan riel positif xi dan yi = dua vektor dalam n Jarak Manhattan \u00b6 Jarak Manhattan adalah jarak antara dua titik diukur sepanjang sumbu di sudut kanan. Pada jarak manhattan sama seperti jarak minkowski, yaitu jarak manhattan sensitif terhadap outlier dengan m = 1. Jarak manhattan digambarkan dengan : $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$ Jarak Euclidean \u00b6 Jarak Euclidean antara dua titik di bidang atau ruang 3 dimensi mengukur panjang segmen yang menghubungkan dua titik. Teorema Pythagoras dapat digunakan untuk menghitung jarak antara dua titik, seperti pada rumus yang berikut ini : $$ \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} $$ Jarak Average \u00b6 Jarak Average adalah jarak yang menggunakan rata-rata dari jarak euclidean untuk memperbaiki hasil. Untuk dua titik yaitu x dan y dalam dimensi n. Jarak Average dapat digambarkan pada rumus : $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$ Jarak Weighted Euclidean \u00b6 Jarak Weighted Euclidean adalah pengukuran jarak dengan menggunakan modifikasi dari jarak Euclidean. Perhitungannya berdasarkan tingkatan penting dari masing-masing atribut yang ditentukan. $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ Keterangan : wi = bobot pada atribut ke i Jarak Chord \u00b6 Jarak Chord adalah cara perhitungan melalui modifikasi jarak Euclidean untuk mengatasi kekurangan dari jarak tersebut. Data yang tidak dinormalisasi juga dapat digunakan untuk Jarak Chord. Jarak Chord dapat dirumuskan sebagai berikut : $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ Jarak Mahalanobis \u00b6 ekstraksi hyperellipsoidal clusters didapat dari Jarak Mahalanobis yang teratur. Distorsi yang disebabkan oleh korelasi linear antara fitur dapat diatasi dengan jarak Mahalanobis. Rumus jarak Mahalanobis dapat digambarkan dengan : $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ Keterangan : S = matrik covariance data","title":"Menghitung Jarak Data"},{"location":"jarak/#menghitung-jarak-data","text":"","title":"Menghitung Jarak Data"},{"location":"jarak/#jarak-minkowski","text":"Jarak Minkowski adalah metrik dalam ruang vektor numerik yang dapat dianggap sebagai generalisasi dari jarak Euclidean dan jarak Manhattan. Jarak Minkowski dapat digambarkan dengan : $$ d _ { \\operatorname { min } } = ( \\ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Keterangan : m = bilangan riel positif xi dan yi = dua vektor dalam n","title":"Jarak Minkowski"},{"location":"jarak/#jarak-manhattan","text":"Jarak Manhattan adalah jarak antara dua titik diukur sepanjang sumbu di sudut kanan. Pada jarak manhattan sama seperti jarak minkowski, yaitu jarak manhattan sensitif terhadap outlier dengan m = 1. Jarak manhattan digambarkan dengan : $$ d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $$","title":"Jarak Manhattan"},{"location":"jarak/#jarak-euclidean","text":"Jarak Euclidean antara dua titik di bidang atau ruang 3 dimensi mengukur panjang segmen yang menghubungkan dua titik. Teorema Pythagoras dapat digunakan untuk menghitung jarak antara dua titik, seperti pada rumus yang berikut ini : $$ \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} $$","title":"Jarak Euclidean"},{"location":"jarak/#jarak-average","text":"Jarak Average adalah jarak yang menggunakan rata-rata dari jarak euclidean untuk memperbaiki hasil. Untuk dua titik yaitu x dan y dalam dimensi n. Jarak Average dapat digambarkan pada rumus : $$ d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } $$","title":"Jarak Average"},{"location":"jarak/#jarak-weighted-euclidean","text":"Jarak Weighted Euclidean adalah pengukuran jarak dengan menggunakan modifikasi dari jarak Euclidean. Perhitungannya berdasarkan tingkatan penting dari masing-masing atribut yang ditentukan. $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ Keterangan : wi = bobot pada atribut ke i","title":"Jarak Weighted Euclidean"},{"location":"jarak/#jarak-chord","text":"Jarak Chord adalah cara perhitungan melalui modifikasi jarak Euclidean untuk mengatasi kekurangan dari jarak tersebut. Data yang tidak dinormalisasi juga dapat digunakan untuk Jarak Chord. Jarak Chord dapat dirumuskan sebagai berikut : $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$","title":"Jarak Chord"},{"location":"jarak/#jarak-mahalanobis","text":"ekstraksi hyperellipsoidal clusters didapat dari Jarak Mahalanobis yang teratur. Distorsi yang disebabkan oleh korelasi linear antara fitur dapat diatasi dengan jarak Mahalanobis. Rumus jarak Mahalanobis dapat digambarkan dengan : $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ Keterangan : S = matrik covariance data","title":"Jarak Mahalanobis"},{"location":"missing value/","text":"Memperlakukan Missing Value Dengan Metode Algoritma K-Nearest Neighbor (KNN) \u00b6 Missing Value \u00b6 Missing value adalah data yang hilang. Dalam arti bahwa, missing value merupakan kekosongan data atau informasi pada suatu objek. Missing value dapat terjadi akibat beberapa faktor. Diantaranya, dapat terjadi karena informasi untuk suatu objek tidak diberikan, tidak ditemukan, atau bahkan tidak dicantumkan. Untuk mencari missing value atau data yang hilang tersebut, kita dapat menggunakan metode Algoritma K-Nearest Neighbor (KKN). K-Nearest Neighbor (KNN) \u00b6 Salah satu usaha untuk memperlakukan missing data yaitu dengan menggunakan Algoritma K-Nearest Neighbor (KNN). Lalu apa yang dimaksud dengan KNN? KNN adalah sebuah metode sederhana untuk mencari missing data dengan menentukan nilai k, dimana nilai k merupakan jarak tetangga terdekat antar data sebagai nilai estimator. Algroritma pada K-Nearest Neighbor (KNN) \u00b6 Langkah utama dalam metode KNN yaitu dengan menghitung nilai k. Nilai k yang dimaksud yaitu jarak tetangga terdekat antar dataset. Kemudian, hasil perhitungan nilai k tersebut menjadi nilai estimator yang digunakan untuk mengisi pada data yang hilang tersebut. Perhitungan untuk mencari nilai k yaitu tergantung dengan jenis data. Apabila data yang disajikan berupa data kontinu, maka menggunakan rata-rata dari tetangga terdekat. Dan apabila data yang disajikan berupa data kualitatif, maka diambil dari nilai yang sering keluar pada objek. Dapat dimisalkan bahwa D merupakan suatu objek yang memiliki kasus missing data. Dengan Dc merupakan subdata yang lengkap, sedangkan Dm merupakan sub data yang memiliki kerumpangan (mengandung atribut yang hilang). Maka, algoritma nya sebagai berikut : Tentukan nilai k Tentukan jarak Masukkan data yang hilang dengan rata-rata (k) dengan tetangga terdekat di Dc Script Missing Value \u00b6 # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 95 , 70 , np . nan , 90 ], 'Second Score' : [ 75 , 70 , 91 , np . nan ], 'Third Score' :[ np . nan , 75 , 85 , 90 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 ) First Score Second Score Third Score 0 95.0 75.0 0.0 1 70.0 70.0 75.0 2 0.0 91.0 85.0 3 90.0 0.0 90.0 \u00b6 \u200b","title":"Missing Value"},{"location":"missing value/#memperlakukan-missing-value-dengan-metode-algoritma-k-nearest-neighbor-knn","text":"","title":"Memperlakukan Missing Value Dengan Metode  Algoritma K-Nearest Neighbor (KNN)"},{"location":"missing value/#missing-value","text":"Missing value adalah data yang hilang. Dalam arti bahwa, missing value merupakan kekosongan data atau informasi pada suatu objek. Missing value dapat terjadi akibat beberapa faktor. Diantaranya, dapat terjadi karena informasi untuk suatu objek tidak diberikan, tidak ditemukan, atau bahkan tidak dicantumkan. Untuk mencari missing value atau data yang hilang tersebut, kita dapat menggunakan metode Algoritma K-Nearest Neighbor (KKN).","title":"Missing Value"},{"location":"missing value/#k-nearest-neighbor-knn","text":"Salah satu usaha untuk memperlakukan missing data yaitu dengan menggunakan Algoritma K-Nearest Neighbor (KNN). Lalu apa yang dimaksud dengan KNN? KNN adalah sebuah metode sederhana untuk mencari missing data dengan menentukan nilai k, dimana nilai k merupakan jarak tetangga terdekat antar data sebagai nilai estimator.","title":"K-Nearest Neighbor (KNN)"},{"location":"missing value/#algroritma-pada-k-nearest-neighbor-knn","text":"Langkah utama dalam metode KNN yaitu dengan menghitung nilai k. Nilai k yang dimaksud yaitu jarak tetangga terdekat antar dataset. Kemudian, hasil perhitungan nilai k tersebut menjadi nilai estimator yang digunakan untuk mengisi pada data yang hilang tersebut. Perhitungan untuk mencari nilai k yaitu tergantung dengan jenis data. Apabila data yang disajikan berupa data kontinu, maka menggunakan rata-rata dari tetangga terdekat. Dan apabila data yang disajikan berupa data kualitatif, maka diambil dari nilai yang sering keluar pada objek. Dapat dimisalkan bahwa D merupakan suatu objek yang memiliki kasus missing data. Dengan Dc merupakan subdata yang lengkap, sedangkan Dm merupakan sub data yang memiliki kerumpangan (mengandung atribut yang hilang). Maka, algoritma nya sebagai berikut : Tentukan nilai k Tentukan jarak Masukkan data yang hilang dengan rata-rata (k) dengan tetangga terdekat di Dc","title":"Algroritma pada K-Nearest Neighbor (KNN)"},{"location":"missing value/#script-missing-value","text":"# importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 95 , 70 , np . nan , 90 ], 'Second Score' : [ 75 , 70 , 91 , np . nan ], 'Third Score' :[ np . nan , 75 , 85 , 90 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 ) First Score Second Score Third Score 0 95.0 75.0 0.0 1 70.0 70.0 75.0 2 0.0 91.0 85.0 3 90.0 0.0 90.0","title":"Script Missing Value"},{"location":"pohon keputusan/","text":"Decision Trees \u00b6 Decision trees atau pohon keputusan adalah alat pendukung keputusan yang menggunakan model keputusan seperti pohon dan kemungkinan konsekuensinya, termasuk hasil acara kebetulan, biaya sumber daya, dan utilitas. Pengertian Decision Trees \u00b6 Pohon keputusan adalah struktur seperti bagan alur di mana setiap simpul internal mewakili \"tes\" pada atribut (misalnya apakah koin balik muncul kepala atau ekor), masing-masing cabang mewakili hasil pengujian, dan setiap simpul daun mewakili label kelas (keputusan diambil setelah menghitung semua atribut). Jalur dari root ke leaf mewakili aturan klasifikasi. Dalam analisis keputusan, pohon keputusan dan diagram terkait erat untuk digunakan sebagai alat pendukung keputusan visual dan analitis, di mana nilai yang diharapkan (atau utilitas yang diharapkan) dari alternatif yang bersaing dihitung. Istilah Dalam Decision Trees \u00b6 Root Node. Mewakili seluruh populasi atau sampel dan ini selanjutnya dibagi menjadi dua set homogen atau lebih. Splitting. Adalah proses membagi node menjadi dua atau lebih sub-node. Decision Node. Adalah ketika sebuah sub-node terbagi menjadi beberapa sub-node. Leaf/ Terminal Node. Adalah node yang tidak terbelah. Pruning. Adalah ketika sub-node terhapus dari node keputusan Branch / Sub-Tree. Adalah sub bagian dari seluruh pohon Parent and Child Node. Adalah sebuah node, yang dibagi menjadi beberapa sub-node disebut node Parent Node dari sub-node sedangkan sub-node adalah Child Node dari Parent Node. Entrophy \u00b6 Entropi adalah nilai informasi yang menyatakan ukuran ketidakpastian(impurity) dari attribut dari suatu kumpulan obyek data dalam satuan bit. Pohon keputusan dibangun dari atas ke bawah dari simpul akar dan melibatkan mempartisi data ke dalam himpunan bagian yang berisi instance dengan nilai yang sama (homogen). $$ E(T) = \\sum_{i=1}^n {-P_i\\log{P_i}} $$ Keterangan : T = ruang sampel data yang digunakan untukdata pelatihan Pi = Probabiliti muncul dalam row Gain \u00b6 Information gain adalah kriteria yang paling populer untuk pemilihan atribut.Pemilihan atribut dilakukan dengan menggunakan Gain Ratio dengan rumus : $$ \\operatorname{Gain}(T, X) = \\operatorname{Entropy}(T) - \\sum_{v\\in{T}} \\frac{T_{X,v}}{T} E(T_{X,v}) $$ Keterangan : Entropy (T) = nilai entropi total dari atribut keputusan dalam ruang sampel data T x = fitur GINI Index \u00b6 Dalam penerapan GINI index untuk data berskala continuous , terdapat beberapa metode yang dapat digunakan untuk menentukan titik pemecah terbaik, yakni metode brute-force dan metode midpoints . Script \u00b6 # menentukan value atau jenis pada atribut def banyak_elemen ( kolom , data ): kelas = [] for i in range ( len ( data )): if data . values . tolist ()[ i ][ kolom ] not in kelas : kelas . append ( data . values . tolist ()[ i ][ kolom ]) return kelas kelas = banyak_elemen ( df . shape [ 1 ] - 1 , df ) outlook = banyak_elemen ( df . shape [ 1 ] - 5 , df ) temp = banyak_elemen ( df . shape [ 1 ] - 4 , df ) humidity = banyak_elemen ( df . shape [ 1 ] - 3 , df ) windy = banyak_elemen ( df . shape [ 1 ] - 2 , df ) print ( kelas , outlook , temp , humidity , windy ) ` [ 'no' , 'yes' ] [ 'sunny' , 'overcast' , 'rainy' ] [ 'hot' , 'mild' , 'cool' ] [ 'high' , 'normal' ] [ False , True ] # menentukan count value pada Kelas #Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class def countvKelas ( kelas , kolomKelas , data ): hasil = [] for x in range ( len ( kelas )): hasil . append ( 0 ) for i in range ( len ( data )): for j in range ( len ( kelas )): if data . values . tolist ()[ i ][ kolomKelas ] == kelas [ j ]: hasil [ j ] += 1 return hasil pKelas = countvKelas ( kelas , df . shape [ 1 ] - 1 , df ) pKelas [ 5 , 9 ] # menentukan nilai entropy target # Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture def entropy ( T ): hasil = 0 jumlah = 0 for y in T : jumlah += y for z in range ( len ( T )): if jumlah != 0 : T [ z ] = T [ z ] / jumlah for i in T : if i != 0 : hasil -= i * math . log ( i , 2 ) return hasil def e_list ( atribut , n ): temp = [] tx = t_list ( atribut , n ) for i in range ( len ( atribut )): ent = entropy ( tx [ i ]) temp . append ( ent ) return temp tOutlook = t_list ( outlook , 5 ) tTemp = t_list ( temp , 4 ) tHum = t_list ( humidity , 3 ) tWin = t_list ( windy , 2 ) print ( \"Sunny, Overcast, Rainy\" , eOutlook ) print ( \"Hot, Mild, Cold\" , eTemp ) print ( \"High, Normal\" , eHum ) print ( \"False, True\" , eWin ) Sunny , Overcast , Rainy [ 0.9709505944546686 , 0.0 , 0.9709505944546686 ] Hot , Mild , Cold [ 1.0 , 0.9182958340544896 , 0.8112781244591328 ] High , Normal [ 0.9852281360342516 , 0.5916727785823275 ] False , True [ 0.8112781244591328 , 1.0 ] Berikut contoh data yang akan di rubah menjadi decision tree : 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari entropy(s) dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitung gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); ## \u200b","title":"Decision Trees"},{"location":"pohon keputusan/#decision-trees","text":"Decision trees atau pohon keputusan adalah alat pendukung keputusan yang menggunakan model keputusan seperti pohon dan kemungkinan konsekuensinya, termasuk hasil acara kebetulan, biaya sumber daya, dan utilitas.","title":"Decision Trees"},{"location":"pohon keputusan/#pengertian-decision-trees","text":"Pohon keputusan adalah struktur seperti bagan alur di mana setiap simpul internal mewakili \"tes\" pada atribut (misalnya apakah koin balik muncul kepala atau ekor), masing-masing cabang mewakili hasil pengujian, dan setiap simpul daun mewakili label kelas (keputusan diambil setelah menghitung semua atribut). Jalur dari root ke leaf mewakili aturan klasifikasi. Dalam analisis keputusan, pohon keputusan dan diagram terkait erat untuk digunakan sebagai alat pendukung keputusan visual dan analitis, di mana nilai yang diharapkan (atau utilitas yang diharapkan) dari alternatif yang bersaing dihitung.","title":"Pengertian Decision Trees"},{"location":"pohon keputusan/#istilah-dalam-decision-trees","text":"Root Node. Mewakili seluruh populasi atau sampel dan ini selanjutnya dibagi menjadi dua set homogen atau lebih. Splitting. Adalah proses membagi node menjadi dua atau lebih sub-node. Decision Node. Adalah ketika sebuah sub-node terbagi menjadi beberapa sub-node. Leaf/ Terminal Node. Adalah node yang tidak terbelah. Pruning. Adalah ketika sub-node terhapus dari node keputusan Branch / Sub-Tree. Adalah sub bagian dari seluruh pohon Parent and Child Node. Adalah sebuah node, yang dibagi menjadi beberapa sub-node disebut node Parent Node dari sub-node sedangkan sub-node adalah Child Node dari Parent Node.","title":"Istilah Dalam Decision Trees"},{"location":"pohon keputusan/#entrophy","text":"Entropi adalah nilai informasi yang menyatakan ukuran ketidakpastian(impurity) dari attribut dari suatu kumpulan obyek data dalam satuan bit. Pohon keputusan dibangun dari atas ke bawah dari simpul akar dan melibatkan mempartisi data ke dalam himpunan bagian yang berisi instance dengan nilai yang sama (homogen). $$ E(T) = \\sum_{i=1}^n {-P_i\\log{P_i}} $$ Keterangan : T = ruang sampel data yang digunakan untukdata pelatihan Pi = Probabiliti muncul dalam row","title":"Entrophy"},{"location":"pohon keputusan/#gain","text":"Information gain adalah kriteria yang paling populer untuk pemilihan atribut.Pemilihan atribut dilakukan dengan menggunakan Gain Ratio dengan rumus : $$ \\operatorname{Gain}(T, X) = \\operatorname{Entropy}(T) - \\sum_{v\\in{T}} \\frac{T_{X,v}}{T} E(T_{X,v}) $$ Keterangan : Entropy (T) = nilai entropi total dari atribut keputusan dalam ruang sampel data T x = fitur","title":"Gain"},{"location":"pohon keputusan/#gini-index","text":"Dalam penerapan GINI index untuk data berskala continuous , terdapat beberapa metode yang dapat digunakan untuk menentukan titik pemecah terbaik, yakni metode brute-force dan metode midpoints .","title":"GINI Index"},{"location":"pohon keputusan/#script","text":"# menentukan value atau jenis pada atribut def banyak_elemen ( kolom , data ): kelas = [] for i in range ( len ( data )): if data . values . tolist ()[ i ][ kolom ] not in kelas : kelas . append ( data . values . tolist ()[ i ][ kolom ]) return kelas kelas = banyak_elemen ( df . shape [ 1 ] - 1 , df ) outlook = banyak_elemen ( df . shape [ 1 ] - 5 , df ) temp = banyak_elemen ( df . shape [ 1 ] - 4 , df ) humidity = banyak_elemen ( df . shape [ 1 ] - 3 , df ) windy = banyak_elemen ( df . shape [ 1 ] - 2 , df ) print ( kelas , outlook , temp , humidity , windy ) ` [ 'no' , 'yes' ] [ 'sunny' , 'overcast' , 'rainy' ] [ 'hot' , 'mild' , 'cool' ] [ 'high' , 'normal' ] [ False , True ] # menentukan count value pada Kelas #Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class def countvKelas ( kelas , kolomKelas , data ): hasil = [] for x in range ( len ( kelas )): hasil . append ( 0 ) for i in range ( len ( data )): for j in range ( len ( kelas )): if data . values . tolist ()[ i ][ kolomKelas ] == kelas [ j ]: hasil [ j ] += 1 return hasil pKelas = countvKelas ( kelas , df . shape [ 1 ] - 1 , df ) pKelas [ 5 , 9 ] # menentukan nilai entropy target # Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture def entropy ( T ): hasil = 0 jumlah = 0 for y in T : jumlah += y for z in range ( len ( T )): if jumlah != 0 : T [ z ] = T [ z ] / jumlah for i in T : if i != 0 : hasil -= i * math . log ( i , 2 ) return hasil def e_list ( atribut , n ): temp = [] tx = t_list ( atribut , n ) for i in range ( len ( atribut )): ent = entropy ( tx [ i ]) temp . append ( ent ) return temp tOutlook = t_list ( outlook , 5 ) tTemp = t_list ( temp , 4 ) tHum = t_list ( humidity , 3 ) tWin = t_list ( windy , 2 ) print ( \"Sunny, Overcast, Rainy\" , eOutlook ) print ( \"Hot, Mild, Cold\" , eTemp ) print ( \"High, Normal\" , eHum ) print ( \"False, True\" , eWin ) Sunny , Overcast , Rainy [ 0.9709505944546686 , 0.0 , 0.9709505944546686 ] Hot , Mild , Cold [ 1.0 , 0.9182958340544896 , 0.8112781244591328 ] High , Normal [ 0.9852281360342516 , 0.5916727785823275 ] False , True [ 0.8112781244591328 , 1.0 ] Berikut contoh data yang akan di rubah menjadi decision tree : 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari entropy(s) dari kolom class di atas diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ lalu kita menghitung gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) =1-(10/20 x 0,970951)+(10/20 x 0,970951) =1-(0,4485475+0,4485475) =1-0,970951 =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) =1-(0,162256+0+0,217426) =1-0,379681 =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) =1-(0,242738+0,34483+0,2+0,2) =1-0,987567 =0,012433 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} }); ## \u200b","title":"Script"},{"location":"regresi/","text":"Regresi Linier Sederhana \u00b6 Pengertian \u00b6 Regresi Linear Sederhana adalah Metode Statistik yang berfungsi untuk menguji sejauh mana hubungan sebab akibat antara Variabel Faktor Penyebab (X) terhadap Variabel Akibatnya. Faktor Penyebab pada umumnya dilambangkan dengan X atau disebut juga dengan Predictor sedangkan Variabel Akibat dilambangkan dengan Y atau disebut juga dengan Response. Regresi Linear Sederhana atau sering disingkat dengan SLR (Simple Linear Regression) juga merupakan salah satu Metode Statistik yang dipergunakan dalam produksi untuk melakukan peramalan ataupun prediksi tentang karakteristik kualitas maupun Kuantitas. Model Persamaan Regresi Linear Sederhana adalah seperti berikut ini : Y = a + bX \u00b6 Dimana : Y = Variabel Response atau Variabel Akibat (Dependent) X = Variabel Predictor atau Variabel Faktor Penyebab (Independent) a = konstanta b = koefisien regresi (kemiringan); besaran Response yang ditimbulkan oleh Predictor. Nilai-nilai a dan b dapat dihitung dengan menggunakan Rumus dibawah ini : a = (\u03a3y) (\u03a3x\u00b2) \u2013 (\u03a3x) (\u03a3xy) n(\u03a3x\u00b2) \u2013 (\u03a3x)\u00b2 b = n(\u03a3xy) \u2013 (\u03a3x) (\u03a3y) n(\u03a3x\u00b2) \u2013 (\u03a3x)\u00b2 Algoritma Regresi Linier Sederhana \u00b6 Berikut ini adalah Langkah-langkah dalam melakukan Analisis Regresi Linear Sederhana : Tentukan Tujuan dari melakukan Analisis Regresi Linear Sederhana Identifikasikan Variabel Faktor Penyebab (Predictor) dan Variabel Akibat (Response) Lakukan Pengumpulan Data Hitung X\u00b2, Y\u00b2, XY dan total dari masing-masingnya Hitung a dan b berdasarkan rumus diatas. Buatkan Model Persamaan Regresi Linear Sederhana. Lakukan Prediksi atau Peramalan terhadap Variabel Faktor Penyebab atau Variabel Akibat. Regresi Linier Berganda \u00b6 Pengertian \u00b6 Analisis regresi linier berganda adalah hubungan secara linear antara dua atau lebih variabel independen (X1, X2,\u2026.Xn) dengan variabel dependen (Y). Analisis ini untuk mengetahui arah hubungan antara variabel independen dengan variabel dependen apakah masing-masing variabel independen berhubungan positif atau negatif dan untuk memprediksi nilai dari variabel dependen apabila nilai variabel independen mengalami kenaikan atau penurunan. Data yang digunakan biasanya berskala interval atau rasio. Model Persamaan Regresi Linear Sederhana adalah seperti berikut ini : Y\u2019 = a + b1X1+ b2X2+\u2026..+ bnXn \u00b6 Keterangan: Y\u2019 = Variabel dependen (nilai yang diprediksikan) X1 dan X2 = Variabel independen a = Konstanta (nilai Y\u2019 apabila X1, X2\u2026..Xn = 0) b = Koefisien regresi (nilai peningkatan ataupun penurunan) Contoh Kasus Dengan Penghitungan Manual \u00b6 Seorang Engineer ingin mempelajari Hubungan antara Suhu Ruangan dengan Jumlah Cacat yang diakibatkannya, sehingga dapat memprediksi atau meramalkan jumlah cacat produksi jika suhu ruangan tersebut tidak terkendali. Engineer tersebut kemudian mengambil data selama 30 hari terhadap rata-rata (mean) suhu ruangan dan Jumlah Cacat Produksi. Penyelesaiannya mengikuti Langkah-langkah dalam Analisis Regresi Linear Sederhana adalah sebagai berikut : Langkah 1 : Penentuan Tujuan \u00b6 Tujuan : Memprediksi Jumlah Cacat Produksi jika suhu ruangan tidak terkendali Langkah 2 : Identifikasikan Variabel Penyebab dan Akibat \u00b6 Varibel Faktor Penyebab (X) : Suhu Ruangan, Variabel Akibat (Y) : Jumlah Cacat Produksi Langkah 3 : Pengumpulan Data \u00b6 Berikut ini adalah data yang berhasil dikumpulkan selama 30 hari (berbentuk tabel) : Tanggal Rata-rata Suhu Ruangan Jumlah Cacat 1 24 10 2 22 5 3 21 6 4 20 3 5 22 6 6 19 4 7 20 5 8 23 9 9 24 11 10 25 13 11 21 7 12 20 4 13 20 6 14 19 3 15 25 12 16 27 13 17 28 16 18 25 12 19 26 14 20 24 12 21 27 16 22 23 9 23 24 13 24 23 11 25 22 7 26 21 5 27 26 12 28 25 11 29 26 13 30 27 14 Langkah 4 : Hitung X\u00b2, Y\u00b2, XY dan total dari masing-masingnya \u00b6 Berikut ini adalah tabel yang telah dilakukan perhitungan X\u00b2, Y\u00b2, XY dan totalnya : Tanggal Rata-rata Suhu Ruangan Jumlah Cacat X2 Y2 XY 1 24 10 576 100 240 2 22 5 484 25 110 3 21 6 441 36 126 4 20 3 400 9 60 5 22 6 484 36 132 6 19 4 361 16 76 7 20 5 400 25 100 8 23 9 529 81 207 9 24 11 576 121 264 10 25 13 625 169 325 11 21 7 441 49 147 12 20 4 400 16 80 13 20 6 400 36 120 14 19 3 361 9 57 15 25 12 625 144 300 16 27 13 729 169 351 17 28 16 784 256 448 18 25 12 625 144 300 19 26 14 676 196 364 20 24 12 576 144 288 21 27 16 729 256 432 22 23 9 529 81 207 23 24 13 576 169 312 24 23 11 529 121 253 25 22 7 484 49 154 26 21 5 441 25 105 27 26 12 676 144 312 28 25 11 625 121 275 29 26 13 676 169 338 30 27 14 729 196 378 Langkah 5 : Hitung a dan b berdasarkan rumus Regresi Linear Sederhana \u00b6 Menghitung Konstanta (a) : a = (\u03a3y) (\u03a3x\u00b2) \u2013 (\u03a3x) (\u03a3xy) n(\u03a3x\u00b2) \u2013 (\u03a3x)\u00b2 a = (282) (16.487) \u2013 (699) (6.861) 30 (16.487) \u2013 (699)\u00b2 a = -24,38 Menghitung Koefisien Regresi (b) b = n(\u03a3xy) \u2013 (\u03a3x) (\u03a3y) n(\u03a3x\u00b2) \u2013 (\u03a3x)\u00b2 b = 30 (6.861) \u2013 (699) (282) 30 (16.487) \u2013 (699)\u00b2 b = 1,45 Langkah 6 : Buat Model Persamaan Regresi \u00b6 Y = a + bX Y = -24,38 + 1,45X Langkah 7 : Lakukan Prediksi atau Peramalan terhadap Variabel Faktor Penyebab atau Variabel Akibat \u00b6 I. Prediksikan Jumlah Cacat Produksi jika suhu dalam keadaan tinggi (Variabel X), contohnya : 30\u00b0C Y = -24,38 + 1,45 (30) Y = 19,12 Jadi Jika Suhu ruangan mencapai 30\u00b0C, maka akan diprediksikan akan terdapat 19,12 unit cacat yang dihasilkan oleh produksi. II. Jika Cacat Produksi (Variabel Y) yang ditargetkan hanya boleh 4 unit, maka berapakah suhu ruangan yang diperlukan untuk mencapai target tersebut ? 4 = -24,38 + 1,45X 1,45X = 4 + 24,38 X = 28,38 / 1,45 X = 19,57 Jadi Prediksi Suhu Ruangan yang paling sesuai untuk mencapai target Cacat Produksi adalah sekitar 19,57\u00b0C Contoh Kasus Dengan Penghitungan Menggunakan Sklearn \u00b6 from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0}; FPC = {1:.2f}' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'series ' + str ( j )) ax2 . legend () newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"Regresi Linier Sederhana"},{"location":"regresi/#regresi-linier-sederhana","text":"","title":"Regresi Linier Sederhana"},{"location":"regresi/#pengertian","text":"Regresi Linear Sederhana adalah Metode Statistik yang berfungsi untuk menguji sejauh mana hubungan sebab akibat antara Variabel Faktor Penyebab (X) terhadap Variabel Akibatnya. Faktor Penyebab pada umumnya dilambangkan dengan X atau disebut juga dengan Predictor sedangkan Variabel Akibat dilambangkan dengan Y atau disebut juga dengan Response. Regresi Linear Sederhana atau sering disingkat dengan SLR (Simple Linear Regression) juga merupakan salah satu Metode Statistik yang dipergunakan dalam produksi untuk melakukan peramalan ataupun prediksi tentang karakteristik kualitas maupun Kuantitas. Model Persamaan Regresi Linear Sederhana adalah seperti berikut ini :","title":"Pengertian"},{"location":"regresi/#y-a-bx","text":"Dimana : Y = Variabel Response atau Variabel Akibat (Dependent) X = Variabel Predictor atau Variabel Faktor Penyebab (Independent) a = konstanta b = koefisien regresi (kemiringan); besaran Response yang ditimbulkan oleh Predictor. Nilai-nilai a dan b dapat dihitung dengan menggunakan Rumus dibawah ini : a = (\u03a3y) (\u03a3x\u00b2) \u2013 (\u03a3x) (\u03a3xy) n(\u03a3x\u00b2) \u2013 (\u03a3x)\u00b2 b = n(\u03a3xy) \u2013 (\u03a3x) (\u03a3y) n(\u03a3x\u00b2) \u2013 (\u03a3x)\u00b2","title":"Y = a + bX"},{"location":"regresi/#algoritma-regresi-linier-sederhana","text":"Berikut ini adalah Langkah-langkah dalam melakukan Analisis Regresi Linear Sederhana : Tentukan Tujuan dari melakukan Analisis Regresi Linear Sederhana Identifikasikan Variabel Faktor Penyebab (Predictor) dan Variabel Akibat (Response) Lakukan Pengumpulan Data Hitung X\u00b2, Y\u00b2, XY dan total dari masing-masingnya Hitung a dan b berdasarkan rumus diatas. Buatkan Model Persamaan Regresi Linear Sederhana. Lakukan Prediksi atau Peramalan terhadap Variabel Faktor Penyebab atau Variabel Akibat.","title":"Algoritma Regresi Linier Sederhana"},{"location":"regresi/#regresi-linier-berganda","text":"","title":"Regresi Linier Berganda"},{"location":"regresi/#pengertian_1","text":"Analisis regresi linier berganda adalah hubungan secara linear antara dua atau lebih variabel independen (X1, X2,\u2026.Xn) dengan variabel dependen (Y). Analisis ini untuk mengetahui arah hubungan antara variabel independen dengan variabel dependen apakah masing-masing variabel independen berhubungan positif atau negatif dan untuk memprediksi nilai dari variabel dependen apabila nilai variabel independen mengalami kenaikan atau penurunan. Data yang digunakan biasanya berskala interval atau rasio. Model Persamaan Regresi Linear Sederhana adalah seperti berikut ini :","title":"Pengertian"},{"location":"regresi/#y-a-b1x1-b2x2-bnxn","text":"Keterangan: Y\u2019 = Variabel dependen (nilai yang diprediksikan) X1 dan X2 = Variabel independen a = Konstanta (nilai Y\u2019 apabila X1, X2\u2026..Xn = 0) b = Koefisien regresi (nilai peningkatan ataupun penurunan)","title":"Y\u2019 = a + b1X1+ b2X2+\u2026..+ bnXn"},{"location":"regresi/#contoh-kasus-dengan-penghitungan-manual","text":"Seorang Engineer ingin mempelajari Hubungan antara Suhu Ruangan dengan Jumlah Cacat yang diakibatkannya, sehingga dapat memprediksi atau meramalkan jumlah cacat produksi jika suhu ruangan tersebut tidak terkendali. Engineer tersebut kemudian mengambil data selama 30 hari terhadap rata-rata (mean) suhu ruangan dan Jumlah Cacat Produksi. Penyelesaiannya mengikuti Langkah-langkah dalam Analisis Regresi Linear Sederhana adalah sebagai berikut :","title":"Contoh Kasus Dengan Penghitungan Manual"},{"location":"regresi/#langkah-1-penentuan-tujuan","text":"Tujuan : Memprediksi Jumlah Cacat Produksi jika suhu ruangan tidak terkendali","title":"Langkah 1 : Penentuan Tujuan"},{"location":"regresi/#langkah-2-identifikasikan-variabel-penyebab-dan-akibat","text":"Varibel Faktor Penyebab (X) : Suhu Ruangan, Variabel Akibat (Y) : Jumlah Cacat Produksi","title":"Langkah 2 : Identifikasikan Variabel Penyebab dan Akibat"},{"location":"regresi/#langkah-3-pengumpulan-data","text":"Berikut ini adalah data yang berhasil dikumpulkan selama 30 hari (berbentuk tabel) : Tanggal Rata-rata Suhu Ruangan Jumlah Cacat 1 24 10 2 22 5 3 21 6 4 20 3 5 22 6 6 19 4 7 20 5 8 23 9 9 24 11 10 25 13 11 21 7 12 20 4 13 20 6 14 19 3 15 25 12 16 27 13 17 28 16 18 25 12 19 26 14 20 24 12 21 27 16 22 23 9 23 24 13 24 23 11 25 22 7 26 21 5 27 26 12 28 25 11 29 26 13 30 27 14","title":"Langkah 3 : Pengumpulan Data"},{"location":"regresi/#langkah-4-hitung-x2-y2-xy-dan-total-dari-masing-masingnya","text":"Berikut ini adalah tabel yang telah dilakukan perhitungan X\u00b2, Y\u00b2, XY dan totalnya : Tanggal Rata-rata Suhu Ruangan Jumlah Cacat X2 Y2 XY 1 24 10 576 100 240 2 22 5 484 25 110 3 21 6 441 36 126 4 20 3 400 9 60 5 22 6 484 36 132 6 19 4 361 16 76 7 20 5 400 25 100 8 23 9 529 81 207 9 24 11 576 121 264 10 25 13 625 169 325 11 21 7 441 49 147 12 20 4 400 16 80 13 20 6 400 36 120 14 19 3 361 9 57 15 25 12 625 144 300 16 27 13 729 169 351 17 28 16 784 256 448 18 25 12 625 144 300 19 26 14 676 196 364 20 24 12 576 144 288 21 27 16 729 256 432 22 23 9 529 81 207 23 24 13 576 169 312 24 23 11 529 121 253 25 22 7 484 49 154 26 21 5 441 25 105 27 26 12 676 144 312 28 25 11 625 121 275 29 26 13 676 169 338 30 27 14 729 196 378","title":"Langkah 4 : Hitung X\u00b2, Y\u00b2, XY dan total dari masing-masingnya"},{"location":"regresi/#langkah-5-hitung-a-dan-b-berdasarkan-rumus-regresi-linear-sederhana","text":"Menghitung Konstanta (a) : a = (\u03a3y) (\u03a3x\u00b2) \u2013 (\u03a3x) (\u03a3xy) n(\u03a3x\u00b2) \u2013 (\u03a3x)\u00b2 a = (282) (16.487) \u2013 (699) (6.861) 30 (16.487) \u2013 (699)\u00b2 a = -24,38 Menghitung Koefisien Regresi (b) b = n(\u03a3xy) \u2013 (\u03a3x) (\u03a3y) n(\u03a3x\u00b2) \u2013 (\u03a3x)\u00b2 b = 30 (6.861) \u2013 (699) (282) 30 (16.487) \u2013 (699)\u00b2 b = 1,45","title":"Langkah 5 : Hitung a dan b berdasarkan rumus Regresi Linear Sederhana"},{"location":"regresi/#langkah-6-buat-model-persamaan-regresi","text":"Y = a + bX Y = -24,38 + 1,45X","title":"Langkah 6 : Buat Model Persamaan Regresi"},{"location":"regresi/#langkah-7-lakukan-prediksi-atau-peramalan-terhadap-variabel-faktor-penyebab-atau-variabel-akibat","text":"I. Prediksikan Jumlah Cacat Produksi jika suhu dalam keadaan tinggi (Variabel X), contohnya : 30\u00b0C Y = -24,38 + 1,45 (30) Y = 19,12 Jadi Jika Suhu ruangan mencapai 30\u00b0C, maka akan diprediksikan akan terdapat 19,12 unit cacat yang dihasilkan oleh produksi. II. Jika Cacat Produksi (Variabel Y) yang ditargetkan hanya boleh 4 unit, maka berapakah suhu ruangan yang diperlukan untuk mencapai target tersebut ? 4 = -24,38 + 1,45X 1,45X = 4 + 24,38 X = 28,38 / 1,45 X = 19,57 Jadi Prediksi Suhu Ruangan yang paling sesuai untuk mencapai target Cacat Produksi adalah sekitar 19,57\u00b0C","title":"Langkah 7 : Lakukan Prediksi atau Peramalan terhadap Variabel Faktor Penyebab atau Variabel Akibat"},{"location":"regresi/#contoh-kasus-dengan-penghitungan-menggunakan-sklearn","text":"from __future__ import division , print_function import numpy as np import matplotlib.pyplot as plt import skfuzzy as fuzz colors = [ 'b' , 'orange' , 'g' , 'r' , 'c' , 'm' , 'y' , 'k' , 'Brown' , 'ForestGreen' ] centers = [[ 4 , 2 ], [ 1 , 7 ], [ 5 , 6 ]] sigmas = [[ 0.8 , 0.3 ], [ 0.3 , 0.5 ], [ 1.1 , 0.7 ]] np . random . seed ( 42 ) xpts = np . zeros ( 1 ) ypts = np . zeros ( 1 ) labels = np . zeros ( 1 ) for i , (( xmu , ymu ), ( xsigma , ysigma )) in enumerate ( zip ( centers , sigmas )): xpts = np . hstack (( xpts , np . random . standard_normal ( 200 ) * xsigma + xmu )) ypts = np . hstack (( ypts , np . random . standard_normal ( 200 ) * ysigma + ymu )) labels = np . hstack (( labels , np . ones ( 200 ) * i )) fig0 , ax0 = plt . subplots () for label in range ( 3 ): ax0 . plot ( xpts [ labels == label ], ypts [ labels == label ], '.' , color = colors [ label ]) ax0 . set_title ( 'Test data: 200 points x3 clusters.' ) fig1 , axes1 = plt . subplots ( 3 , 3 , figsize = ( 8 , 8 )) alldata = np . vstack (( xpts , ypts )) fpcs = [] for ncenters , ax in enumerate ( axes1 . reshape ( - 1 ), 2 ): cntr , u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans ( alldata , ncenters , 2 , error = 0.005 , maxiter = 1000 , init = None ) fpcs . append ( fpc ) cluster_membership = np . argmax ( u , axis = 0 ) for j in range ( ncenters ): ax . plot ( xpts [ cluster_membership == j ], ypts [ cluster_membership == j ], '.' , color = colors [ j ]) # Mark the center of each fuzzy cluster for pt in cntr : ax . plot ( pt [ 0 ], pt [ 1 ], 'rs' ) ax . set_title ( 'Centers = {0}; FPC = {1:.2f}' . format ( ncenters , fpc )) ax . axis ( 'off' ) fig1 . tight_layout () fig2 , ax2 = plt . subplots () ax2 . plot ( np . r_ [ 2 : 11 ], fpcs ) ax2 . set_xlabel ( \"Number of centers\" ) ax2 . set_ylabel ( \"Fuzzy partition coefficient\" ) cntr , u_orig , _ , _ , _ , _ , _ = fuzz . cluster . cmeans ( alldata , 3 , 2 , error = 0.005 , maxiter = 1000 ) # Show 3-cluster model fig2 , ax2 = plt . subplots () ax2 . set_title ( 'Trained model' ) for j in range ( 3 ): ax2 . plot ( alldata [ 0 , u_orig . argmax ( axis = 0 ) == j ], alldata [ 1 , u_orig . argmax ( axis = 0 ) == j ], 'o' , label = 'series ' + str ( j )) ax2 . legend () newdata = np . random . uniform ( 0 , 1 , ( 1100 , 2 )) * 10 u , u0 , d , jm , p , fpc = fuzz . cluster . cmeans_predict ( newdata . T , cntr , 2 , error = 0.005 , maxiter = 1000 ) cluster_membership = np . argmax ( u , axis = 0 ) fig3 , ax3 = plt . subplots () ax3 . set_title ( 'Random points classifed according to known centers' ) for j in range ( 3 ): ax3 . plot ( newdata [ cluster_membership == j , 0 ], newdata [ cluster_membership == j , 1 ], 'o' , label = 'series ' + str ( j )) ax3 . legend () plt . show ()","title":"Contoh Kasus Dengan Penghitungan Menggunakan Sklearn"},{"location":"statistik deskriptif/","text":"Statistik Deskriptif \u00b6 Pengertian \u00b6 Statistika Deskriptif merupakan metode yang berkaitan dengan pengumpulan dan penyajian data sehingga memberikan informasi. Statististika deskriptif hanya memberikan informasi yang disediakan dan tidak menarik kesimpulan apapun tentang yang lainnya. Tipe Statistik Deskriptif \u00b6 Mean ( Rata-Rata ) \u00b6 Mean merupakan rata-rata dari beberapa data yang tersedia. Mean dalam data juga merupakan statistik karena bisa menampilkan kisaran dari beberapa data yang ditentukan. Berikut adalah rumusnya : $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Keterangan : x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data Median ( Nilai Tengah ) \u00b6 Median merupakan nilai tengah yang ada pada data-data yang telah ditentukan. Median memiliki dua jenis rumus dalam perhitungannya, yaitu untuk data yanng berjumlah ganjil dan data yang berjumlah genap. Berikut adalah rumus nya : $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Keterangan : Me = Median dari data n = Banyak data Modus (Nilai Sering Keluar) \u00b6 Modus adalah nilai yang sering keluar dalam kumpulan data - data yang telah tersedia. $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Keterangan : Mo = Modus dari kelompok data b1 = selisih frekuensi antar elemen modus dengan elemen sebelumnya b2 = selisih frekuensi antara elemen modus dengan elemen sesudahnya Tb = tepi bawah dari elemen modus b1 p = panjang interval Varians \u00b6 Varians adalah parameter yang menjelaskan tentang distribusi probabilitas. Varian berguna mengukur seberapa jauh sebuah kumpulan bilangan tersebar. Berikut cara menghitungnya : $$ \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$ Skewnes \u00b6 Skewnes merupakan kemiringan dalam suatu kurva. Skewnes adalah derajat ketidak simetrisan suatu distribusi. Berikut cara menghitungnya : $$ Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ xi = titik data x bar = rata-rata dari distribusi n = jumlah titik dalam distribusi o = standar deviasi Quartile \u00b6 Quartile merupakan nilai - nilai yang membagi data dalam 4 bagian yang sama. terdapat tiga jenis quartile, yaitu quartile pertama, kedua, dan ketiga. Adapun cara mencari atau menghitungnya yaitu : $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ Keterangan : Q = Nilai dari quartile n = banyak dari himpunan data Penerapan Statistik Deskriptif Menggunakan Python \u00b6 Alat dan Bahan \u00b6 Pada kasus ini, terdapat file .csv yang berisi 500 data random yang dibuat dari Ms. Excel terlebih dahulu. Untuk selanjutnya, dibutuhkan library python. Library python yang dibutuhkan antara lain Pandas dan Scipy. Penerapan \u00b6 import pandas as pd from scipy import stats df = pd . read_csv ( \"sekolah.csv\" , sep = ';' ) data = { \"Stats\" :[ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data , columns = [ 'Stats' ] + [ x for x in df . columns ]) tes Hasil Running \u00b6 Stats MATEMATIKA BAHASA INDONESIA BAHASA INGGRIS IPA 0 Min 60.000000 65.000000 55.000000 60.000000 1 Max 100.000000 100.000000 100.000000 100.000000 2 Mean 80.308617 81.927856 77.859719 79.230461 3 Standard Deviasi 11.920000 10.340000 12.810000 11.730000 4 Variasi 142.110000 106.860000 164.030000 137.610000 5 Skewnes -0.050000 0.100000 0.010000 0.050000 6 Quantile 1 71.000000 73.000000 67.000000 69.000000 7 Quantile 2 81.000000 81.000000 78.000000 79.000000 8 Quantile 3 90.000000 91.000000 88.000000 89.000000 9 Median 81.000000 81.000000 78.000000 79.000000 10 Modus 60.000000 78.000000 86.000000 61.000000 MathJax.Hub.Config({ tex2jax: {inlineMath:[['$$','$$']]} });","title":"Statistik Deskriptif"},{"location":"statistik deskriptif/#statistik-deskriptif","text":"","title":"Statistik Deskriptif"},{"location":"statistik deskriptif/#pengertian","text":"Statistika Deskriptif merupakan metode yang berkaitan dengan pengumpulan dan penyajian data sehingga memberikan informasi. Statististika deskriptif hanya memberikan informasi yang disediakan dan tidak menarik kesimpulan apapun tentang yang lainnya.","title":"Pengertian"},{"location":"statistik deskriptif/#tipe-statistik-deskriptif","text":"","title":"Tipe Statistik Deskriptif"},{"location":"statistik deskriptif/#mean-rata-rata","text":"Mean merupakan rata-rata dari beberapa data yang tersedia. Mean dalam data juga merupakan statistik karena bisa menampilkan kisaran dari beberapa data yang ditentukan. Berikut adalah rumusnya : $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Keterangan : x = data ke n x bar = x rata-rata = nilai rata-rata sampel n = banyaknya data","title":"Mean ( Rata-Rata )"},{"location":"statistik deskriptif/#median-nilai-tengah","text":"Median merupakan nilai tengah yang ada pada data-data yang telah ditentukan. Median memiliki dua jenis rumus dalam perhitungannya, yaitu untuk data yanng berjumlah ganjil dan data yang berjumlah genap. Berikut adalah rumus nya : $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Keterangan : Me = Median dari data n = Banyak data","title":"Median ( Nilai Tengah )"},{"location":"statistik deskriptif/#modus-nilai-sering-keluar","text":"Modus adalah nilai yang sering keluar dalam kumpulan data - data yang telah tersedia. $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Keterangan : Mo = Modus dari kelompok data b1 = selisih frekuensi antar elemen modus dengan elemen sebelumnya b2 = selisih frekuensi antara elemen modus dengan elemen sesudahnya Tb = tepi bawah dari elemen modus b1 p = panjang interval","title":"Modus (Nilai Sering Keluar)"},{"location":"statistik deskriptif/#varians","text":"Varians adalah parameter yang menjelaskan tentang distribusi probabilitas. Varian berguna mengukur seberapa jauh sebuah kumpulan bilangan tersebar. Berikut cara menghitungnya : $$ \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$","title":"Varians"},{"location":"statistik deskriptif/#skewnes","text":"Skewnes merupakan kemiringan dalam suatu kurva. Skewnes adalah derajat ketidak simetrisan suatu distribusi. Berikut cara menghitungnya : $$ Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ xi = titik data x bar = rata-rata dari distribusi n = jumlah titik dalam distribusi o = standar deviasi","title":"Skewnes"},{"location":"statistik deskriptif/#quartile","text":"Quartile merupakan nilai - nilai yang membagi data dalam 4 bagian yang sama. terdapat tiga jenis quartile, yaitu quartile pertama, kedua, dan ketiga. Adapun cara mencari atau menghitungnya yaitu : $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2 = (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ Keterangan : Q = Nilai dari quartile n = banyak dari himpunan data","title":"Quartile"},{"location":"statistik deskriptif/#penerapan-statistik-deskriptif-menggunakan-python","text":"","title":"Penerapan Statistik Deskriptif Menggunakan Python"},{"location":"statistik deskriptif/#alat-dan-bahan","text":"Pada kasus ini, terdapat file .csv yang berisi 500 data random yang dibuat dari Ms. Excel terlebih dahulu. Untuk selanjutnya, dibutuhkan library python. Library python yang dibutuhkan antara lain Pandas dan Scipy.","title":"Alat dan Bahan"},{"location":"statistik deskriptif/#penerapan","text":"import pandas as pd from scipy import stats df = pd . read_csv ( \"sekolah.csv\" , sep = ';' ) data = { \"Stats\" :[ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quantile 1' , 'Quantile 2' , 'Quantile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data , columns = [ 'Stats' ] + [ x for x in df . columns ]) tes","title":"Penerapan"},{"location":"statistik deskriptif/#hasil-running","text":"Stats MATEMATIKA BAHASA INDONESIA BAHASA INGGRIS IPA 0 Min 60.000000 65.000000 55.000000 60.000000 1 Max 100.000000 100.000000 100.000000 100.000000 2 Mean 80.308617 81.927856 77.859719 79.230461 3 Standard Deviasi 11.920000 10.340000 12.810000 11.730000 4 Variasi 142.110000 106.860000 164.030000 137.610000 5 Skewnes -0.050000 0.100000 0.010000 0.050000 6 Quantile 1 71.000000 73.000000 67.000000 69.000000 7 Quantile 2 81.000000 81.000000 78.000000 79.000000 8 Quantile 3 90.000000 91.000000 88.000000 89.000000 9 Median 81.000000 81.000000 78.000000 79.000000 10 Modus 60.000000 78.000000 86.000000 61.000000 MathJax.Hub.Config({ tex2jax: {inlineMath:[['$$','$$']]} });","title":"Hasil Running"}]}